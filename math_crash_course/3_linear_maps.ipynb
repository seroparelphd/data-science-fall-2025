{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash Course Lesson 3\n",
    "\n",
    "In this lesson we learn about:\n",
    "\n",
    "* **Linear Transformations** from $\\mathbb{R}^n$ to $\\mathbb{R}^m$.\n",
    "* What a **matrix** is.\n",
    "* Three different perspectives on the matrix vector product $A \\vec{x}$:\n",
    "    * As a linear transformation applied to $\\vec{x}$.\n",
    "    * As a linear combination of the columns of $A$, weighted by the components of $\\vec{x}$.\n",
    "    * As the dot product of the rows of $A$ with $\\vec{x}$.\n",
    "* How to rephrase everything we learned in LA1 and LA2 using the three different perspectives\n",
    "* Understanding **matrix multiplication** as composition of linear maps.\n",
    "* The **inverse** of a matrix.\n",
    "* The **transpose** of a matrix $A^\\top$.\n",
    "* The **four fundamental subspaces** of a matrix $A$ and their interrelationships:\n",
    "    * The **column space** which is the span of the columns of $A$.\n",
    "    * The **row space** which is the span of the columns of $A^\\top$ (which are the rows of $A$).\n",
    "    * The **null space** which is set of solutions of $A\\vec{x} = \\vec{0}$.\n",
    "    * The **left null space** which is the set of solutions of $A^\\top \\vec{y} = \\vec{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**:  A **linear transformation** is any function $L : \\mathbb{R}^n \\to \\mathbb{R}^m$ which satisfies the following two conditions:\n",
    "* Respects vector sums: If $\\vec{v},\\vec{w} \\in \\mathbb{R}^n$ are any two vectors then\n",
    "$$\n",
    "L(\\vec{v} + \\vec{w}) = L(\\vec{v}) + L(\\vec{w})\n",
    "$$\n",
    "* Respects scalar multiplication: If $c \\in \\mathbb{R}$ is any scalar and $\\vec{v} \\in \\mathbb{R}^n$ is any vector then\n",
    "$$\n",
    "L(c\\vec{v}) = cL(\\vec{v})\n",
    "$$\n",
    "\n",
    "Note:  we could have combined these two conditions, and just said \"$L$ respects linear combinations\".  Could you write that intuitively phrased condition as a formal equation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**:  Let $L: \\mathbb{R}^2 \\to \\mathbb{R}^3$ be a linear map.  Say you know that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L\\left( \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\right) &= \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\\\\\n",
    "L\\left( \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right) &= \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "* Use the properties of linear transformations to figure out $L\\left( \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\right)$.\n",
    "* Use the properties of linear transformations to figure out $L\\left( \\begin{bmatrix} x \\\\ y \\end{bmatrix}\\right)$ for any two real numbers $x$ and $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did the exercise you might now find the following idea to be believable:\n",
    "\n",
    "**Idea**:  If you know the outputs of a linear transforation $L: \\mathbb{R}^n \\to \\mathbb{R}^m$ for each of the standard basis vectors $\\vec{e}_1, \\vec{e}_2, \\vec{e}_3, ..., \\vec{e}_n$, then you can figure out what the output of $L$ is for *any* input by taking an appropriate linear combination of the basis vector outputs.\n",
    "\n",
    "We record this information in a **matrix** (2 dimensional array of numbers) as follows:\n",
    "\n",
    "Let $L: \\mathbb{R}^n \\to \\mathbb{R}^m$. The **matrix of $L$ with respect to the standard basis** (which we will write $M_L$) is an array of numbers with $m$ rows and $n$ columns.  The $j^{th}$ column is the output of the linear transformation when the input is $\\vec{e}_j$.\n",
    "\n",
    "$$\n",
    "M_L = \n",
    "\\begin{bmatrix}\n",
    "\\vert & \\vert & \\vert & \\dots & \\vert\\\\\n",
    "L(\\vec{e}_1) & L(\\vec{e}_2) & L(\\vec{e}_3) & ... & L(\\vec{e}_n)\\\\\n",
    "\\vert & \\vert & \\vert & \\dots & \\vert\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "M_{1,1} & M_{1,2} & M_{1,3} & \\dots & M_{1,n}\\\\\n",
    "M_{2,1} & M_{2,2} & M_{2,3} & \\dots & M_{2,n}\\\\\n",
    "& & & \\vdots & \\\\\n",
    "M_{m,1} & M_{m,2} & M_{m,3} & \\dots & M_{m,n}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note the convention that we are introducing here:  the entry of the matrix $M_{i,j}$ is in the $i^{th}$ row and $j^{th}$ column. \n",
    "\n",
    "**Example**:  The linear transformation we introduced in the exercise had\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L\\left( \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\right) &= \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\\\\\n",
    "L\\left( \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right) &= \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So the matrix would be \n",
    "\n",
    "$$\n",
    "M_L = \\begin{bmatrix}1 & 1\\\\ 2 & -1 \\\\ 3 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For an example of indexing conventions: $M_{1,2} = 1$ and $M_{2,1} = 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**:  Let $L: \\mathbb{R}^n \\to \\mathbb{R}^m $ be the linear transformation with matrix\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix}\n",
    " 1 & 2 & 3 & 4\\\\\n",
    " 5 & 6 & 7 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* What is the dimension of the domain (aka what is $n$)?  What is the dimension of the codomain (aka what is $m$)?\n",
    "* What is the output of the vector whose coordinates are all $1$ from the domain?\n",
    "* Find a non-zero vector which is mapped to $\\vec{0}$ by $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice**:  Try as many of [these exercises ](https://teambasedinquirylearning.github.io/linear-algebra/2023/exercises/#/bank/AT1/1/) and  [these exercises](https://teambasedinquirylearning.github.io/linear-algebra/2023/exercises/#/bank/AT2/1/) as you want until you feel comfortable understanding linear transformations, the matrix of a linear transformation, and how to multiply a matrix by a vector.  Work both by hand and with NumPy.\n",
    "\n",
    "Hint: to multiply the matrix $M$ by the vector $v$ in NumPy use np.dot(M,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain a geometric understanding of linear maps, I highly recommend watching [this 3Blue1Brown video](https://www.youtube.com/watch?v=kYB8IZa5AuE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three Perspectives** on matrix-vector products:\n",
    "\n",
    "Consider the matrix vector product \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6\\end{bmatrix} \\begin{bmatrix} 7 \\\\ 8 \\\\ 9\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We can think of this three different ways:\n",
    "\n",
    "1. We can think of it as a linear trasformation $L : \\mathbb{R}^3 \\to \\mathbb{R}^2$ being applied to a vector in $\\mathbb{R}^3$.  From this perspective, the matrix is taking 3D space and \"smashing it\" onto 2D space in such a way that parallelograms always get mapped to paralelleograms.  The one vector we are plugging in is just coming along for the ride.\n",
    "\n",
    "2. We can think of it as a linear combination of the columns of the matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6\\end{bmatrix} \\begin{bmatrix} 7 \\\\ 8 \\\\ 9\\end{bmatrix} = 7 \\begin{bmatrix}1 \\\\ 4 \\end{bmatrix}  + 8 \\begin{bmatrix} 2 \\\\ 5\\end{bmatrix} + 9 \\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "from this perspective the matrix is just a list of column vectors, and a matrix-vector product is a recipe for giving a desired linear combination of the columns vectors.\n",
    "\n",
    "3. We can think of it as dotting the rows of the matrix with the vector:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6\\end{bmatrix} \\begin{bmatrix} 7 \\\\ 8 \\\\ 9\\end{bmatrix} = \\begin{bmatrix} 1(7) + 2(8) + 3(9) \\\\ 4(7) + 5(8) + 6(9)\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is a little harder to interpret, but is an especially useful perspective when $M \\vec{v} = 0$:  it says that the rows of $M$ are all perpendicular to the vector $\\vec{v}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define matrix multiplication so that it corresponds to composition of the associated linear maps:\n",
    "\n",
    "**Definition**:  Let $A$ be an $n \\times m$ matrix and $B$ be an $k \\times n$ matrix.  Then we have associated linear maps $L_A: \\mathbb{R}^m \\to \\mathbb{R}^n$ and $L_B: \\mathbb{R}^n \\to \\mathbb{R}^k$.  We define the matrix product  $BA$ to be the matrix of the linear map $L_B \\circ L_A: \\mathbb{R}^m \\to \\mathbb{R}^n$.\n",
    "\n",
    "In other words, if $A$ has columns $\\vec{c}_1, \\vec{c}_2, \\vec{c}_3, \\dots, \\vec{c}_m \\in \\mathbb{R}^n$, so that\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    " \\vert & \\vert & \\vert & \\dots & \\vert\\\\\n",
    " \\vec{c}_1  &  \\vec{c}_2  &  \\vec{c}_3  &  \\dots  &  \\vec{c}_m  \\\\\n",
    "  \\vert & \\vert & \\vert & \\dots & \\vert\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then \n",
    "\n",
    "$$\n",
    "BA = \n",
    "\\begin{bmatrix}\n",
    " \\vert & \\vert & \\vert & \\dots & \\vert\\\\\n",
    " B\\vec{c}_1  &  B\\vec{c}_2  &  B\\vec{c}_3  &  \\dots  &  B\\vec{c}_m  \\\\\n",
    "  \\vert & \\vert & \\vert & \\dots & \\vert\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If $B$ has rows $\\vec{r}_1, \\vec{r}_2, \\vec{r}_3, \\dots \\vec{r}_n$, so that\n",
    "\n",
    "$$\n",
    "B  = \n",
    "\\begin{bmatrix} \n",
    "\\rule[.5ex]{3.5em}{0.4pt} & \\vec{r}_1 &  \\rule[.5ex]{3.5em}{0.4pt}\\\\\n",
    "\\rule[.5ex]{3.5em}{0.4pt} & \\vec{r}_2 &  \\rule[.5ex]{3.5em}{0.4pt}\\\\\n",
    "\\rule[.5ex]{3.5em}{0.4pt} & \\vec{r}_3 &  \\rule[.5ex]{3.5em}{0.4pt}\\\\\n",
    "\\rule[.5ex]{3.5em}{0.4pt} & \\vdots &  \\rule[.5ex]{3.5em}{0.4pt}\\\\\n",
    "\\rule[.5ex]{3.5em}{0.4pt} & \\vec{r}_n &  \\rule[.5ex]{3.5em}{0.4pt}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then we have\n",
    "\n",
    "$BA = \\begin{bmatrix} \n",
    "\\vec{r}_1 \\cdot \\vec{c}_1 & \\vec{r}_1 \\cdot \\vec{c}_2 & \\vec{r}_1 \\cdot \\vec{c}_3 & \\dots & \\vec{r}_1 \\cdot \\vec{c}_m\\\\\n",
    "\\vec{r}_2 \\cdot \\vec{c}_1 & \\vec{r}_2 \\cdot \\vec{c}_2 & \\vec{r}_2 \\cdot \\vec{c}_3 & \\dots & \\vec{r}_2 \\cdot \\vec{c}_m\\\\\n",
    "\\vec{r}_3 \\cdot \\vec{c}_1 & \\vec{r}_3 \\cdot \\vec{c}_2 & \\vec{r}_3 \\cdot \\vec{c}_3 & \\dots & \\vec{r}_3 \\cdot \\vec{c}_m\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "\\vec{r}_n \\cdot \\vec{c}_1 & \\vec{r}_n \\cdot \\vec{c}_2 & \\vec{r}_n \\cdot \\vec{c}_3 & \\dots & \\vec{r}_n \\cdot \\vec{c}_m\\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice**:  Try as many of [these exercises](https://teambasedinquirylearning.github.io/linear-algebra/2023/exercises/#/bank/MX1/1/) as you want, both by hand and using NumPy, until you feel comfortable with matrix multiplication.\n",
    "\n",
    "Hint:  the numpy code for the matrix product $BA$ is np.dot(B,A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**:  The $n\\times n$ **identity** matrix is the $n \\times n$ matrix $I$ with ones on the diagonal.  It has the property that for any $k \\times n$ matrix $A$ or $n \\times k$ matrix $B$ we have\n",
    "\n",
    "$$\n",
    "AI = A\n",
    "$$\n",
    "\n",
    "$$\n",
    "IB = B\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Example:\n",
    "\n",
    "A = np.random.random((2,3))\n",
    "B = np.random.random((3,2))\n",
    "I = np.eye(3)\n",
    "\n",
    "#If A is equal to AI and IA, both of the following will be True.\n",
    "\n",
    "print(np.array_equal(A, np.dot(A,I)), np.array_equal(B, np.dot(I,B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**:  Let  $A$ be an $n \\times n$ matrix.  $A$  **has an inverse** if and only if there is a matrix $A^{-1}$ with\n",
    "\n",
    "$$\n",
    "AA^{-1} = A^{-1}A = I\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is \n",
      " [[1.18991450e-01 4.75920505e-01 8.84478968e-01 8.54399392e-02\n",
      "  1.17582013e-01]\n",
      " [3.96987954e-02 9.41267488e-01 4.57710041e-01 8.46848802e-01\n",
      "  6.23257425e-04]\n",
      " [7.87653555e-01 5.03543033e-01 7.97327498e-01 8.53321324e-01\n",
      "  6.63456076e-01]\n",
      " [5.53349912e-01 5.44573296e-01 3.19998403e-01 7.39816710e-01\n",
      "  1.64055084e-01]\n",
      " [9.32238423e-01 8.99669016e-01 9.75981682e-01 8.16359179e-01\n",
      "  2.02184540e-01]]\n",
      "The inverse of A is \n",
      " [[ -10.49889363    4.32744479    3.38650446  -20.14054562   11.32206186]\n",
      " [ -51.21146545   28.38218893   19.52941591 -106.5781967    52.08926006]\n",
      " [  31.28845542  -16.56262247  -11.68369822   62.48164291  -30.5040502 ]\n",
      " [  40.53069821  -21.63227504  -15.56301531   85.69398391  -41.96836817]\n",
      " [ -38.39920731   21.04877119   16.72257366  -80.50624143   37.66213943]]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "A =  np.random.random((5,5))\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "print(\"A is \\n\", A)\n",
    "print(\"The inverse of A is \\n\",A_inv)\n",
    "\n",
    "# The following are both True if A Ainv = I and Ainv A = I\n",
    "print(np.array_equal(np.eye(5), np.round(np.dot(A,A_inv)), 5))\n",
    "print(np.array_equal(np.eye(5), np.round(np.dot(A_inv,A),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**:  an $n \\times n$ matrix has an inverse if and only if its columns form a basis of $\\mathbb{R}^n$.\n",
    "\n",
    "This should make some intuitive sense from perspective 2:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textrm{Columns of $A$ form a basis} \n",
    "&\\Longleftrightarrow \\textrm{The columns of $A$ are linearly independent and span $\\mathbb{R}^n$}\\\\\n",
    "&\\Longleftrightarrow \\textrm{For every vector $\\vec{v}$ in $\\mathbb{R}^n$ there is one and only one linear combination of the columns yielding that vector}\\\\\n",
    "&\\Longleftrightarrow \\textrm{For every vector $\\vec{v}$ in $\\mathbb{R}^n$ there is one and only one vector $\\vec{\\beta}$ for which $A\\vec{\\beta} = \\vec{v}$ }\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**:  The inverse of a matrix is useful for solving a system of equations, when it exists.\n",
    "\n",
    "For example to solve\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "x + y + z &= 6\\\\\n",
    "x - y - 2z&= 4\\\\\n",
    "3x + 2y + z = 7\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "you can reformulate this as\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & -1 & -2 \\\\ 3 & 2 & 1 \\end{bmatrix}  \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 4 \\\\ 7\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and apply the inverse of the matrix (which I will call $A$) to both sides on the left to get\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = A^{-1} \\begin{bmatrix} 6 \\\\ 4 \\\\ 7\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15.]\n",
      " [-29.]\n",
      " [ 20.]]\n",
      "checking\n",
      "15  +  -29  +  20  =  6\n",
      "15  -( -29 ) -2( 20 ) =  4\n",
      "3( 15 ) + 2( -29 ) +  20  =  7\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,1,1],[1,-1,-2],[3,2,1]])\n",
    "Ainv = np.linalg.inv(A)\n",
    "v = np.array([[6],[4],[7]])\n",
    "solution = np.dot(Ainv,v)\n",
    "print(solution)\n",
    "print(\"checking\")\n",
    "print(int(solution[0,0]), \" + \", int(solution[1,0]), \" + \", int(solution[2,0]), \" = \", v[0,0])\n",
    "print(int(solution[0,0]), \" -(\", int(solution[1,0]), \") -2(\", int(solution[2,0]), \") = \", v[1,0])\n",
    "print(\"3(\", int(solution[0,0]), \") + 2(\", int(solution[1,0]), \") + \", int(solution[2,0]), \" = \", v[2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition**:  The **transpose** of an $m \\times n$ matrix $A$ is the $n \\times m$ matrix $A^\\top$ whose entries have their indices flipped.  In other words, the rows of $A$ are the columns of $A^\\top$. For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 &  2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}^\\top = \\begin{bmatrix} 1 & 4 \\\\ 2 & 5 \\\\ 3 & 6 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is \n",
      " [[-9  8  0]\n",
      " [ 5 -3  1]]\n",
      "The transpose of A is \n",
      " [[-9  5]\n",
      " [ 8 -3]\n",
      " [ 0  1]]\n"
     ]
    }
   ],
   "source": [
    "# python example\n",
    "\n",
    "A = np.random.randint(-10,10,(2,3))\n",
    "print('A is \\n', A)\n",
    "print('The transpose of A is \\n', np.transpose(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**:  If you want to find all of the vectors perpendicular to the span of the columns of $A$, this is equivalent to finding all of the vectors which are mapped to $0$ by $A^\\top$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A^\\top \\vec{v} = 0 \n",
    "&\\Longleftrightarrow \\vec{v} \\cdot \\textrm{(every row of $A^\\top$)} = 0 \\textrm{ , by ``perspective 3\"}\\\\\n",
    "&\\Longleftrightarrow \\vec{v} \\cdot \\textrm{(every column of $A$)} = 0 \\textrm{ , since rows of $A^\\top$ are columns of $A$}\\\\\n",
    "&\\Longleftrightarrow \\vec{v} \\textrm{ is orthogonal to the span of the columns of $A$}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important relationship**:  if $\\vec{x} \\in \\mathbb{R}^n$, $\\vec{y} \\in \\mathbb{R}^m$ and $A$ is a $m \\times n$ matrix, then  \n",
    "\n",
    "$$\n",
    "\\vec{y} \\cdot A\\vec{x} = A^\\top \\vec{y} \\cdot \\vec{x}\n",
    "$$\n",
    "\n",
    "or (using the alternative notation for dot products)\n",
    "\n",
    "$$\n",
    "\\langle \\vec{y}, A  \\vec{x}\\rangle = \\langle A^\\top \\vec{y}, \\vec{x} \\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definitions**:\n",
    "\n",
    "* The **image** of a linear transformation $L: \\mathbb{R}^n \\to \\mathbb{R}^m$ is the collection of all vectors in $\\vec{w} \\in \\mathbb{R}^m$ for which we can find a $\\vec{v} \\in \\mathbb{R}^n$ with $L(\\vec{v}) = \\vec{w}$. It is a subspace of $\\mathbb{R}^m$. You may have heard the same concept referred to as the \"range\" in a pre-Calculus or Calculus class.\n",
    "    * Note:  From \"perspective 2\" on matrix-vector products, we can also think of this as the span of the columns.  For this reason the image of the linear transformation is also called the **column space** of the associated matrix.\n",
    "    * Note: We will use the notation $\\textrm{Im}(L)$ (read:  \"image of $L$\")interchangeably with $\\textrm{Col}(M_L)$ (read: \"Column space of $M_L$\").\n",
    "* The **null space** of a linear transformation $L : \\mathbb{R}^n \\to \\mathbb{R}^m$ is the collection of all vectors $\\vec{v} \\in \\mathbb{R}^n$ which are sent to $\\vec{0}$ by $L$.  It is a subspace of $\\mathbb{R}^n$.  We will write $\\textrm{Null}(L)$ or $\\textrm{Null}(M_L)$ for this subspace.\n",
    "    * Note:  If $\\textrm{Null}(L) \\neq \\{\\vec{0}\\}$, then (using perspective 2 again) this says that some linear combination of the columns of $M_L$ is linearly dependent.  On the other hand if $\\textrm{Null}(L) = \\{\\vec{0}\\}$, then the columns of $L$ are linearly independent.  You can also check that this is equivalent to the map $L$ being one-to-one.\n",
    "* The **row space** of  $A$ is the column space of $A^\\top$.  In other words, it is the span of the rows of $A$.  We will just write $\\textrm{Col}(A^\\top)$ for this space.\n",
    "* The **left null space** of $A$ is the null space of $A^\\top$.  We will just write $\\textrm{Null}(A^\\top)$ for this space.\n",
    "    * Earlier we said \"If you want to find all of the vectors perpendicular to the span of the columns of $A$, this is equivalent to finding all of the vectors which are mapped to $0$ by $A^\\top$\".  We can rephrase this as $\\textrm{Null}(A^\\top) = \\textrm{Col}(A)^\\perp$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these ideas to write a new implementation of the orthogonal projection function we wrote in the second lesson which does **not** rely on Gram-Schmidt.\n",
    "\n",
    "Say we have a vector $\\vec{y} \\in \\mathbb{R}^m$.  We also have vectors $\\vec{y}_1, \\vec{y}_2, ..., \\vec{y}_n \\in \\mathbb{R}^m$.  We want to project $\\vec{y}$ onto the span of $\\vec{y}_1, \\vec{y}_2, ..., \\vec{y}_n$.\n",
    "\n",
    "Let $A$ be the $m \\times n$ matrix with columns $\\vec{y}_1, \\vec{y}_2, ..., \\vec{y}_n$.  Then we can restate our problem using the new vocabulary as \"We want to project $\\vec{y}$ onto the column space of $A$\".\n",
    "\n",
    "Call the projected vector $\\hat{y}$, and let $\\vec{r} = \\vec{y} - \\hat{y}$.\n",
    "\n",
    "Since $\\hat{y} \\in \\textrm{Col}(A)$, we know that $\\hat{y}$ is a linear combination of the columns of $A$.  However, using the equivalence of perspectives $1$ and $2$, we can interpret this as meaning that there is a vector $\\vec{\\beta} \\in \\mathbb{R}^n$ with $\\hat{y} = A \\vec{\\beta}$.\n",
    "\n",
    "We want $\\vec{r}$ to be perpendicular to the column of $A$.  We explain this is equivalent to $\\vec{r}$ being in the null space of $A^\\top$.\n",
    "\n",
    "Putting it together we want\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A^\\top (\\vec{y}  - A \\vec{\\beta}) &= \\vec{0}\\\\\n",
    "A^\\top \\vec{y} = A^\\top A \\vec{\\beta} \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If the columns of $A$ are linearly independent, then $A^\\top A$ (a square matrix!) will be invertible, and we can solve\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\vec{\\beta} &= (A^\\top A)^{-1} A^\\top \\vec{y}\\\\\n",
    "A\\vec{\\beta} &= A(A^\\top A)^{-1} A^\\top \\vec{y}\\\\\n",
    "\\hat{y} &=  A(A^\\top A)^{-1} A^\\top \\vec{y}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So we have the following formula for the projection of a vector $\\vec{y}$ onto the column space of the matrix $A$ (assuming these columns are linearly independent):\n",
    "\n",
    "$$\n",
    "\\textrm{proj}_{\\textrm{Col}(A)} (\\vec{y}) = A(A^\\top A)^{-1} A^\\top \\vec{y}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Implement \n",
    "\n",
    "$$\n",
    "\\textrm{proj}_{\\textrm{Col}(A)} (\\vec{y}) = A(A^\\top A)^{-1} A^\\top \\vec{y}\n",
    "$$\n",
    "\n",
    "as a python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A and y are be numpy arrays\n",
    "\n",
    "#def proj(A, y):\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1**:  Let $L: \\mathbb{R}^2 \\to \\mathbb{R}^3$ be a linear map.  Say you know that\n",
    "> \n",
    "> $$\n",
    "> \\begin{align*}\n",
    "> L\\left( \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\right) &= \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\\\\\n",
    "> L\\left( \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right) &= \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\\\\n",
    "> \\end{align*}\n",
    "> $$\n",
    "> \n",
    "> * Use the properties of linear transformations to figure out $L\\left( \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\right)$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L\\left( \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\\right) \n",
    "&=  L\\left( \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right) \\\\\n",
    "&=  L\\left( \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} \\right) +  L\\left(\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right)  \\textrm{ since $L$ respects vector sums}\\\\\n",
    "&=  L\\left( 2\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right) +  L\\left(\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right)\\\\\n",
    "&=  2L\\left( \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right) +  L\\left(\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right) \\textrm{ since $L$ respects scalar multiplication}\\\\\n",
    "&=2\\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix} + \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix} 3 \\\\ 3 \\\\ 7\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "> * Use the properties of linear transformations to figure out $L\\left( \\begin{bmatrix} x \\\\ y \\end{bmatrix}\\right)$ for any two real numbers $x$ and $y$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L\\left( \\begin{bmatrix} x \\\\ y \\end{bmatrix}\\right) \n",
    "&=  L\\left( \\begin{bmatrix} x \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ y \\end{bmatrix}\\right) \\\\\n",
    "&=  L\\left( \\begin{bmatrix} x \\\\ 0 \\end{bmatrix} \\right) +  L\\left(\\begin{bmatrix} 0 \\\\ y \\end{bmatrix}\\right)  \\textrm{ since $L$ respects vector sums}\\\\\n",
    "&=  L\\left( x \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right) +  L\\left( y \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right)\\\\\n",
    "&=  xL\\left( \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right) +  yL\\left(\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\right) \\textrm{ since $L$ respects scalar multiplication}\\\\\n",
    "&=x\\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix} + y\\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix} x+ y \\\\ 2x-y \\\\ 3x + y\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2**:  Let $L: \\mathbb{R}^n \\to \\mathbb{R}^m $ be the linear transformation with matrix\n",
    "> \n",
    "> $$\n",
    "> M = \\begin{bmatrix}\n",
    ">  1 & 2 & 3 & 4\\\\\n",
    "> 5 & 6 & 7 & 8\n",
    "> \\end{bmatrix}\n",
    "> $$\n",
    "> \n",
    "> * What is the dimension of the domain (aka what is $n$)?  What is the dimension of the codomain (aka what is $m$)?\n",
    "\n",
    "Each column corresponds to the output of a standard basis vector of the domain.  Since there are 4 columns, we must have $n = 4$.  Since each column is 2 dimensional we have $m = 2$.\n",
    "\n",
    "> * What is the output of the vector whose coordinates are all $1$ from the domain?\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L\\left( \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}\\right) \n",
    "&= L\\left( \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\right)  + L\\left( \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\\right) +  L\\left( \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}\\right) +  L\\left( \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\right)\\\\\n",
    "& = \\begin{bmatrix} 1 \\\\ 5\\end{bmatrix} + \\begin{bmatrix} 2 \\\\ 6\\end{bmatrix} +  \\begin{bmatrix} 3 \\\\ 7\\end{bmatrix} + \\begin{bmatrix} 4 \\\\ 8\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix} 10 \\\\ 26 \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "> * Find a non-zero vector which is mapped to $\\vec{0}$ by $L$.\n",
    "\n",
    "Let $\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix}$ be a vector which is mapped to $\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ by $L$.  We have\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L\\left( \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix}\\right) \n",
    "&= x_1L\\left( \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\\right)  + x_2L\\left( \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\\right) +  x_3L\\left( \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}\\right) +  x_4L\\left( \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\right)\\\\\n",
    "& = x_1\\begin{bmatrix} 1 \\\\ 5\\end{bmatrix} + x_2\\begin{bmatrix} 2 \\\\ 6\\end{bmatrix} +  x_3\\begin{bmatrix} 3 \\\\ 7\\end{bmatrix} + x_4\\begin{bmatrix} 4 \\\\ 8\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix} x_1 + 2x_2 + 3x_3 + 4x_4 \\\\ 5x_1 + 6x_2 + 7x_3 + 8x_4 \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So we need to find solutions to \n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "1x_1 + 2x_2 + 3x_3 + 4x_4 &= 0\\\\\n",
    "5x_1 + 6x_2 + 7x_3 + 8x_4 &= 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We can solve this with SymPy to get all the solutions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left\\{\\left( x_{3} + 2 x_{4}, \\  - 2 x_{3} - 3 x_{4}, \\  x_{3}, \\  x_{4}\\right)\\right\\}$"
      ],
      "text/plain": [
       "{(x_3 + 2*x_4, -2*x_3 - 3*x_4, x_3, x_4)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import linsolve, symbols\n",
    "x_1, x_2, x_3, x_4 = symbols(\"x_1, x_2, x_3,x_4\")\n",
    "Eqns = [1*x_1 + 2*x_2 + 3*x_3 + 4*x_4, 5*x_1 + 6*x_2 + 7*x_3 + 8*x_4]\n",
    "linsolve(Eqns, x_1, x_2, x_3, x_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can let $x_3$ and $x_4$ be anything we like and get a solution this way.  To be explicit about it, let's get one solution with $x_3 = 1$ and $x_4 = 0$.  Then $x_1 = 1$ and $x_2 = -2$ so \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "-2\\\\\n",
    "1\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "is one solution.  Similarly \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2\\\\\n",
    "-3\\\\\n",
    "0\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "is another solution, and together these two vectors span the space of all possible solutions (we will learn that this is called the \"null space\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 3**: Implement \n",
    "> \n",
    "> $$\n",
    "> \\textrm{proj}_{\\textrm{Col}(A)} (\\vec{y}) = A(A^\\top A)^{-1} A^\\top \\vec{y}\n",
    "> $$\n",
    "> \n",
    "> as a python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A and y are numpy arrays\n",
    "\n",
    "def proj(A, y):\n",
    "    At = np.transpose(A)\n",
    "    AtA = np.dot(At, A)\n",
    "    AtAinv = np.linalg.inv(AtA)\n",
    "    matrices = [A, AtAinv, At, y]\n",
    "    y_hat = np.linalg.multi_dot(matrices)\n",
    "    return y_hat\n",
    "\n",
    "# Note:  you can test that this gives you the same results as the much more complicated function orthoproj from the LA2-dot-product notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
