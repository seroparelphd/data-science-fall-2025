{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55fd5a6",
   "metadata": {},
   "source": [
    "# Problem Session 4\n",
    "\n",
    "The problems in this notebook will cover the content covered in our Regression lectures including:\n",
    "- Regularization\n",
    "- Principle Component Analysis\n",
    "- Categorical Variables and Interactions\n",
    "- Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36624b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We first load in packages we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbeaf12",
   "metadata": {},
   "source": [
    "#### 1. Practice creating mock data and fitting models to it\n",
    "\n",
    "Creating your own fake data and fitting models to that data is a good way to practice.  It is nice because you have access to the \"ground truth\" when you make your own data.\n",
    "\n",
    "Another more practical usage of simulation is parametric bootstrapping, which we will cover in a few lectures.\n",
    "\n",
    "It is also *very common* to need to mock up some data during an interview.\n",
    "\n",
    "##### a.  \n",
    "\n",
    "We will start by creating a design matrix $X$ with $20$ rows and $10$ columns whose first $9$ columns are all quite close to each other.  The last column will be distinct, so that X is \"close to\" being a rank 2 matrix.  \n",
    "\n",
    "Then we will have $y$ be the sum of all columns plus some noise.\n",
    "\n",
    "So the true functional relationship is just to sum all the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1b65477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nobs is short for \"number of observations\"\n",
    "nobs = 20\n",
    "\n",
    "# A numpy array of shape (nobs,) whose entries are drawn uniformly from the interval [0,10]\n",
    "x = \n",
    "\n",
    "# A numpy array of shape (nobs, 10).  Each column should be x plus normal errors with standard deviation 0.1\n",
    "# Note that we will overwrite the final column in the next step.\n",
    "# Hint: use np.tile.  Look up the docs!\n",
    "X = \n",
    "\n",
    "# Overwrite the last column of X with new independent draws from [0,10]\n",
    "\n",
    "\n",
    "# A numpy array of shape (nobs,) which is equal to the sum of the columns of X plus normal errors of variance 1.\n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ae6c4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a train test split.  Don't specify a random state this time!  We will be rerunning this later.\n",
    "from sklearn.model_selection import \n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffe7dd",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "We will now fit a standard linear regression, ridge regression, and PCA regression model to the data.  We want to compare mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "50e9dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import \n",
    "from sklearn.decomposition import \n",
    "from sklearn.pipeline import \n",
    "from sklearn.preprocessing import \n",
    "from sklearn.metrics import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1694274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models. Which ones need scaling?  Use 2 components for the PCA.\n",
    "lr = \n",
    "ridge_pipe = \n",
    "pca_pipe = \n",
    "\n",
    "# Fit the models to the training data\n",
    "\n",
    "# Find the model predictions on the training set\n",
    "lr_train_preds = \n",
    "ridge_train_preds = \n",
    "pca_train_preds = \n",
    "\n",
    "# Find the model predictions on the test set\n",
    "lr_test_preds = \n",
    "ridge_test_preds = \n",
    "pca_test_preds = \n",
    "\n",
    "# Find the mse on the training set\n",
    "lr_train_mse = \n",
    "ridge_train_mse = \n",
    "pca_train_mse = \n",
    "\n",
    "# Find the mse on the test set\n",
    "lr_test_mse = \n",
    "ridge_test_mse =\n",
    "pca_test_mse =\n",
    "\n",
    "# Results\n",
    "print(f\"OLS Training MSE: {lr_train_mse}\")\n",
    "print(f\"Ridge Training MSE: {ridge_train_mse}\")\n",
    "print(f\"PCA Training MSE: {pca_train_mse}\")\n",
    "print(f\"OLS Test MSE: {lr_test_mse}\")\n",
    "print(f\"Ridge Test MSE: {ridge_test_mse}\")\n",
    "print(f\"PCA Test MSE: {pca_test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5db2e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to click \"run all above\" a number of times.  Discuss with your group.\n",
    "# Will OLS always outperform the other two models on the training set?  Will it ever outperform on the testing set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15b638",
   "metadata": {},
   "source": [
    "#### c.\n",
    "\n",
    "Lasso deals with multicollinearity poorly in the sense that it will often \"randomly\" choose which columns to keep and which to discard.  So we should expect that Lasso will keep the last feature (which is not correlated with the first $9$), and randomly choose from the first $9$.  Let's see if that pans out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f6aba17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91966e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for the Lasso hyperparameter\n",
    "alphas = np.exp(np.linspace(-6,-1,8))\n",
    "\n",
    "# coefs will store the lasso coefficients.  One row for each alpha, one column for each coefficient.\n",
    "coefs = np.zeros((len(alphas), 10))\n",
    "\n",
    "for i,alpha in enumerate(alphas):\n",
    "    # Make a pipeline where you first scale and then lasso.\n",
    "    # Use max_iter=100000 in your Lasso to avoid some convergence issues.\n",
    "    lasso_pipe = \n",
    "\n",
    "    # Fit it to the training data\n",
    "\n",
    "    # Store the coefficients in the ith row of coefs.  Replace the ?s appropriately \n",
    "    coefs[?,?] = \n",
    "\n",
    "# Just to make the display of coefs nicer I put them in a dataframe.\n",
    "pd.DataFrame(coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbcdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to click \"run all above\" a number of times.  Discuss with your group.\n",
    "# Does Lasso always select feature 9?  Is the choice of other features to keep consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf5f47",
   "metadata": {},
   "source": [
    "#### Bonus \n",
    "\n",
    "Only do this if you got done with everything above in the first 20 minutes or so.  Otherwise come back to it at the end.\n",
    "\n",
    "Write a function which repeats everything from part (a) and (b) above 1000 times and records how often Ridge beats OLS and PCA regression beats OLS on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787a82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81245eec",
   "metadata": {},
   "source": [
    "Note:  If you only got through part 1 in this problem session that is fine.  You have already rehearsed all of the skills from lecture, and hopefully had a few insights as well.\n",
    "\n",
    "The next part is therefore \"optional\".  I am including it for the groups that are really speedy.  It also feels bad to have a problem session without real data!  You can certainly treat part 2 as \"homework\" if you run have out of time.\n",
    "\n",
    "The new dataset also doesn't really seem to benefit much from regularization, so the new techniques from this week are not very rewarding.  Think of it as just more regression practice.  There is also one new idea of \"controlling for a variable\" which is introduced in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96926347",
   "metadata": {},
   "source": [
    "#### 2. The diamonds dataset\n",
    "\n",
    "We introduce a new \"classic\" dataset.  Our task is to predict the price of diamonds.\n",
    "\n",
    "* price: Price in US dollars.\n",
    "* carat: Weight of the diamond.\n",
    "* cut: Cut quality (ordered worst to best).\n",
    "* color: Color of the diamond (ordered best to worst).\n",
    "* clarity: Clarity of the diamond (ordered worst to best).\n",
    "* x: Length in mm.\n",
    "* y: Width in mm.\n",
    "* z: Depth in mm.\n",
    "* depth: Total depth percentage: 100 * z / mean(x, y)\n",
    "* table: Width of the top of the diamond relative to the widest point.\n",
    "\n",
    "Homepage: https://ggplot2.tidyverse.org/reference/diamonds.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d85f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/diamonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f63cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49e703",
   "metadata": {},
   "source": [
    "For sake of time we will restrict ourselves to just one categorical feature (`cut`) and one continuous feature (`carat`) in our modeling.  This is only being done for pedagogical purposes!  In a real situation you would want to carefully explore all of the data you have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd649b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['cut', 'carat', 'price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0f471",
   "metadata": {},
   "source": [
    "#### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1b037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a train/test split with 20% of data held aside as the test set.\n",
    "from sklearn.model_selection import \n",
    "\n",
    "df_train, df_test = \n",
    "\n",
    "X_train = \n",
    "X_test = \n",
    "y_train = \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff756d66",
   "metadata": {},
   "source": [
    "##### b. \n",
    "\n",
    "What are the percentage of samples belonging to each level of the `cut` feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a35bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22819624",
   "metadata": {},
   "source": [
    "##### c. \n",
    "\n",
    "Look at the distribution of price at each level of the `cut` feature.  Do you notice anything strange or unexpected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da57154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6179da07",
   "metadata": {},
   "source": [
    "##### d. \n",
    "\n",
    "One thing which might be a bit confusing is that the cut quality does not seem to be a very good indicator of price.  Why might that be?\n",
    "\n",
    "Sometimes this happens when two predictors which each have a positive **causal** impact on the outcome are negatively correlated with each other.  In other words, it might be that **all else being equal** a higher quality cut will increase the price, and a larger carat will increase the price, but higher quality cuts are negatively correlated with the size in carats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade84074",
   "metadata": {},
   "source": [
    "Use the `groupby` and `describe` methods to look at some summary statistics of carat size sorted by cut quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb29ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfbc8392",
   "metadata": {},
   "source": [
    "We can see that the \"Fair\" quality also has the largest mean carat size, while \"Ideal\" quality has the smallest. I am not a domain expert, but this could be due to jewelers needing to cut away more of the original stone to produce better cuts?  This would be something to consult with a jeweler on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075b73a",
   "metadata": {},
   "source": [
    "##### e.\n",
    "\n",
    "Graph price against carat with color coded by cut quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5766cf9",
   "metadata": {},
   "source": [
    "##### f.\n",
    "\n",
    "The relationship you obtained above does not look linear.  Graph the log of the price against the log of the carat size.  This should look substantially more linear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58368265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_price'] = \n",
    "df_train['log_carat'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e67212b",
   "metadata": {},
   "source": [
    "##### g.\n",
    "\n",
    "We do not have the ability to **experimentally** adjust `cut` and `carat` independently to see the impact on price, but we can still use **statistical control**.\n",
    "\n",
    "We will run a linear regression of `log_price` against `cut` and `log_carat`.  Do better cuts contribute to higher prices when controlling for carat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d6daaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8709b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuss what you think preprocessor does with your team.  Can you test that it does what you think it should?\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(), ['cut']),\n",
    "        ('identity', FunctionTransformer(func = None), ['log_carat'])\n",
    "        ])\n",
    "\n",
    "# Write a pipeline which first uses preprocessor and then uses LinearRegression(fit_intercept = False). \n",
    "# Why do I not want to fit the intercept term?\n",
    "model = \n",
    "\n",
    "# Fit it on the training set using the 'cut' and 'log_carat'features (in that order).\n",
    "\n",
    "# It is a bit difficult to access the feature names of one part of a pipeline, so I have done it for you.\n",
    "one_hot_feature_names = model.named_steps['preprocess'].named_transformers_['cat'].get_feature_names_out(['cut'])\n",
    "feature_names = np.append(one_hot_feature_names, ['log_carat'])  # Manually add log_carat\n",
    "\n",
    "# Map coefficients to feature names and sort them\n",
    "cut_adjustments = pd.Series(model.named_steps['linear'].coef_, index=feature_names).sort_values()\n",
    "\n",
    "cut_adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9afbbf",
   "metadata": {},
   "source": [
    "#### h. Evaluating residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf69127",
   "metadata": {},
   "source": [
    "Make a plot of residuals against predicted values.  Discuss the implications for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e61d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25dc8102",
   "metadata": {},
   "source": [
    "The lines in the residual plot are due to the apparent thresholds on price in the training data.  Prices seem to have a soft cap at around $18k and a soft minimum of around $350."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147583f",
   "metadata": {},
   "source": [
    "#### i. Quantifying model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b9d57",
   "metadata": {},
   "source": [
    "Let's use [mean absolute percentage error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html) and [mean absolute error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) as our performance metrics.  \n",
    "\n",
    "Remember to use these in the units of the original target, not the transformed target!\n",
    "\n",
    "How does our model perform on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85751f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf48d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
